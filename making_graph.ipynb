{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we remove NaN's and \\\\N values from the dataset, but only where it matters, i.e. at IATA (airport code), latitude, longitude, country and city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = [\"id\", \"city\", \"country\", \"IATA\", \"ICAO\", \"latitude\", \"longitude\", \"altitude\", \"timezone\", \"DST\", \"Tz database time zone\", \"type\", \"source\"]\n",
    "cols_to_remove = [\"ICAO\", \"altitude\", \"timezone\", \"DST\", \"Tz database time zone\", \"type\", \"source\"]\n",
    "airports = pd.read_csv('data/airports.csv', index_col=0, names=cols, header=None)\n",
    "airports = airports.drop(cols_to_remove, axis=1)\n",
    "print(len(airports))\n",
    "\n",
    "subset = [\"IATA\", \"latitude\", \"longitude\", \"country\", \"city\"]\n",
    "airports = airports.dropna(subset=subset)\n",
    "for col in subset:\n",
    "    airports = airports[airports[col] != \"\\\\N\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make a dictionary mapping from country to continent, such that we can add continent to the above dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abkhazia': 'Asia',\n",
       " 'Afghanistan': 'Asia',\n",
       " 'Akrotiri and Dhekelia': 'Asia',\n",
       " 'Aland Islands': 'Europe',\n",
       " 'Albania': 'Europe'}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents = pd.read_csv('data/continents.csv')\n",
    "## make a dictionary of country to continent\n",
    "country_to_continent = {}\n",
    "for index, row in continents.iterrows():\n",
    "    country = row['Entity']\n",
    "    country_to_continent[row['Entity']] = row['Continent']\n",
    "    \n",
    "## show the first 5 entries of the dictionary\n",
    "dict(list(country_to_continent.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, we make a dictionary that maps from country to BNP, such that this can be added to the dataframe aswell. \n",
    "We only consider BNP from 2015, since this also around the time that the reviews are  gathered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Afghanistan': 2108.714,\n",
       " 'Albania': 11880.598,\n",
       " 'Algeria': 11751.634,\n",
       " 'Angola': 7967.104,\n",
       " 'Antigua and Barbuda': 19345.018}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNP_per_capita = pd.read_csv('data/gdp-per-capita-worldbank.csv')\n",
    "BNP_per_capita_2015 = BNP_per_capita[BNP_per_capita[\"Year\"] == 2015]\n",
    "## make a dictionary of country to BNP per capita\n",
    "country_to_BNP_per_capita = {}\n",
    "for index, row in BNP_per_capita_2015.iterrows():\n",
    "    country = row['Entity']\n",
    "    country_to_BNP_per_capita[country] = row['GDP per capita, PPP (constant 2017 international $)']\n",
    "## see first 5 entries of the dictionary\n",
    "dict(list(country_to_BNP_per_capita.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of continents/BNP comes from Our World In Data (owid), and it doesn't match with the country names from the airport dataset. Therefore, we manually have to fix these names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These names should be fixed:\n",
      "Congo (Brazzaville)\n",
      "Congo (Kinshasa)\n",
      "Swaziland\n",
      "Czech Republic\n",
      "Macedonia\n",
      "Midway Islands\n",
      "Micronesia\n",
      "Virgin Islands\n",
      "Macau\n",
      "Burma\n",
      "Johnston Atoll\n",
      "Cocos (Keeling) Islands\n",
      "Wake Island\n"
     ]
    }
   ],
   "source": [
    "countries_from_airports = airports['country'].unique()\n",
    "countries_from_continents = continents['Entity'].unique()\n",
    "countries_from_BNP = BNP_per_capita_2015['Entity'].unique()\n",
    "## make a set of unique countries from continents and BNP\n",
    "unique_countries = set(countries_from_continents).union(set(countries_from_BNP))\n",
    "unique_countries = list(unique_countries)\n",
    "\n",
    "## find the countries that are in airports but not in continents\n",
    "print(\"These names should be fixed:\")\n",
    "for country in countries_from_airports:\n",
    "    if country not in unique_countries:\n",
    "        print(country)\n",
    "        \n",
    "def fix_country_name(name : str) -> str:\n",
    "    \"\"\"\n",
    "    Function for matching up the country names in the airports dataset with the country names in the continents dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    if name[:5] == \"Congo\":\n",
    "        return \"Congo\"\n",
    "    \n",
    "    if name == \"Czech Republic\":\n",
    "        return \"Czechia\"\n",
    "    \n",
    "    if name == \"Macedonia\":\n",
    "        return \"North Macedonia\"\n",
    "    \n",
    "    if name == \"Swaziland\":\n",
    "        return \"Eswatini\"\n",
    "    \n",
    "    if name == \"Micronesia\":\n",
    "        return \"Micronesia (country)\"\n",
    "    \n",
    "    if name == \"Burma\":\n",
    "        return \"Myanmar\"\n",
    "    \n",
    "    if name in [\"Midway Islands\", \"US Virgin Islands\", \"Virgin Islands\", \"Johnston Atoll\", \"Wake Island\"]:\n",
    "        return \"United States\"\n",
    "    \n",
    "    if name == \"Macau\":\n",
    "        return \"China\"\n",
    "    \n",
    "    if name == \"Cocos (Keeling) Islands\":\n",
    "        return \"Australia\"\n",
    "    \n",
    "    if name == \"Russian Federation\":\n",
    "        return \"Russia\"\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a new column in the airports dataset with the continent\n",
    "airports['continent'] = airports['country'].apply(fix_country_name).map(country_to_continent)\n",
    "## same for the BNP per capita\n",
    "airports['BNP per capita'] = airports['country'].apply(fix_country_name).map(country_to_BNP_per_capita)\n",
    "## if the BNP is a nan, fill it with the mean\n",
    "airports['BNP per capita'] = airports['BNP per capita'].fillna(airports['BNP per capita'].mean())\n",
    "## save the dataset\n",
    "airports.to_csv('data/airports_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17721/17721 [02:59<00:00, 98.64it/s]  \n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "from functools import cache\n",
    "tqdm.pandas()\n",
    "\n",
    "def format_name(name):\n",
    "    name = name.replace(\"-\", \" \")\n",
    "    ## make first letter in each word uppercase\n",
    "    name = \" \".join([word.capitalize() for word in name.split()])\n",
    "    return name\n",
    "\n",
    "@cache\n",
    "def match_name(name, candidates):\n",
    "    name = format_name(name)\n",
    "    if name in candidates:\n",
    "        return name\n",
    "    \n",
    "    ## get the best match\n",
    "    match, score = process.extractOne(name, candidates)\n",
    "    if score > 90:\n",
    "        return match\n",
    "    \n",
    "    return None\n",
    "\n",
    "airportreviews = pd.read_csv(\"data/airportreviews.csv\")\n",
    "cols_to_keep = [\"airport_name\", \"recommended\", \"content\"]\n",
    "airportreviews = airportreviews[cols_to_keep]\n",
    "airportreviews = airportreviews.dropna(subset=cols_to_keep)\n",
    "\n",
    "candidates = airports['id'].unique()\n",
    "candidates = tuple(candidates)\n",
    "airportreviews[\"matched_name\"] = airportreviews[\"airport_name\"].progress_apply(lambda x: match_name(x, candidates))\n",
    "airportreviews = airportreviews.dropna(subset=[\"matched_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each airport in airports dataframe, insert the average recommendation score from airportsreviews\n",
    "airportreviews[\"recommended\"] = airportreviews[\"recommended\"].astype(int)\n",
    "average_recommendation = airportreviews.groupby(\"matched_name\")[\"recommended\"].mean()\n",
    "reviews_as_list = airportreviews.groupby(\"matched_name\")[\"content\"].apply(list).reset_index()\n",
    "\n",
    "airports = pd.merge(airports, reviews_as_list, how=\"left\", left_on=\"id\", right_on=\"matched_name\")\n",
    "airports = pd.merge(airports, average_recommendation, how=\"left\", left_on=\"id\", right_on=\"matched_name\")\n",
    "\n",
    "## change column name to \"average_recommendation\"\n",
    "airports = airports.rename(columns={\"recommended\": \"average_recommendation\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the dictionaries, we can fill in BNP and continents of the airports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GKA {'city': 'Goroka', 'country': 'Papua New Guinea', 'latitude': -6.081689834590001, 'longitude': 145.391998291, 'name': 'Goroka Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "MAG {'city': 'Madang', 'country': 'Papua New Guinea', 'latitude': -5.20707988739, 'longitude': 145.789001465, 'name': 'Madang Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "HGU {'city': 'Mount Hagen', 'country': 'Papua New Guinea', 'latitude': -5.826789855957031, 'longitude': 144.29600524902344, 'name': 'Mount Hagen Kagamuga Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "LAE {'city': 'Nadzab', 'country': 'Papua New Guinea', 'latitude': -6.569803, 'longitude': 146.725977, 'name': 'Nadzab Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "POM {'city': 'Port Moresby', 'country': 'Papua New Guinea', 'latitude': -9.44338035583496, 'longitude': 147.22000122070312, 'name': 'Port Moresby Jacksons International Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "WWK {'city': 'Wewak', 'country': 'Papua New Guinea', 'latitude': -3.58383011818, 'longitude': 143.669006348, 'name': 'Wewak International Airport', 'continent': 'Oceania', 'BNP_per_capita': 3813.1143, 'average_recommendation': nan}\n",
      "...\n",
      "Number of airports in each continent:\n",
      "{'Oceania': 521, 'North America': 1952, 'Europe': 1066, 'Africa': 626, 'South America': 572, 'Asia': 1295, 'Antarctica': 1}\n"
     ]
    }
   ],
   "source": [
    "## make a dictionary of IATA codes\n",
    "## IATA code is a three-letter code designating many airports around the world\n",
    "## for each airport, safe relevant information in a dictionary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "IATA = {}\n",
    "for index, row in airports.iterrows():\n",
    "    country = row['country']\n",
    "    \n",
    "    IATA[row['IATA']] = {\n",
    "        'city': row['city'],                                                ## city\n",
    "        'country': country,                                                 ## country\n",
    "        'latitude': row['latitude'],                                        ## latitude\n",
    "        'longitude': row['longitude'],                                      ## longitude\n",
    "        'name': row['id'],                                                  ## name        \n",
    "        'continent': country_to_continent.get(fix_country_name(country), 'unknown'),    ## continent\n",
    "        'BNP_per_capita': country_to_BNP_per_capita.get(fix_country_name(country), 'unknown'), ## BNP per capita\n",
    "        'average_recommendation' : row['average_recommendation'],           ## average recommendation\n",
    "    }\n",
    "    \n",
    "## save the dictionary to a file\n",
    "import json\n",
    "with open('data/IATA.json', 'w') as f:\n",
    "    json.dump(IATA, f)\n",
    "\n",
    "## show the first 5 entries of the dictionary\n",
    "for i, (k, v) in enumerate(IATA.items()):\n",
    "    print(k, v)\n",
    "    if i == 5:\n",
    "        break\n",
    "print(\"...\")\n",
    "    \n",
    "## count how many airports are in each continent\n",
    "continent_count = {}\n",
    "for k, v in IATA.items():\n",
    "    continent = v['continent']\n",
    "\n",
    "    if continent not in continent_count:\n",
    "        continent_count[continent] = 0\n",
    "    continent_count[continent] += 1\n",
    "    \n",
    "print(\"Number of airports in each continent:\")\n",
    "print(continent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique airport names in reviews: 425\n"
     ]
    }
   ],
   "source": [
    "## find all unique airport names\n",
    "airports_in_reviews = reviews['airport_name'].unique()\n",
    "print(\"Number of unique airport names in reviews:\", len(airports_in_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique airport names in dataset: 6007\n"
     ]
    }
   ],
   "source": [
    "airports_in_dataset = airports[\"id\"].apply(lambda x: x.lower()).unique().tolist()\n",
    "print(\"Number of unique airport names in dataset:\", len(airports_in_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ærø airport\n",
      "altenburg nobitz airport\n",
      "maritsa airport\n",
      "bantayan airport\n",
      "jastarnia airport\n",
      "mangalore airport\n",
      "relizane airport\n",
      "berlin schönefeld airport\n",
      "berlin tegel airport\n",
      "birmingham shuttlesworth international airport\n",
      "vumbura airport\n",
      "embu airport\n",
      "metropolitano airport\n",
      "clear airport\n",
      "cleve airport\n",
      "colorado springs east airport\n",
      "chofu airport\n",
      "tobago crown point airport\n",
      "cutral co airport\n",
      "denali airport\n",
      "djibouti ambouli airport\n",
      "edmundston airport\n",
      "fairoaks airport\n",
      "frankfurt hahn airport\n",
      "greytown airport\n",
      "gothenburg landvetter airport\n",
      "grenoble isère airport\n",
      "hanko airport\n",
      "hancock county bar harbor airport\n",
      "burg airport\n",
      "princeton airport\n",
      "john wayne airport orange county airport\n",
      "kabale airport\n",
      "tokachi airport\n",
      "karlshöfen airport\n",
      "kazarman airport\n",
      "west kilimanjaro airport\n",
      "kidston airport\n",
      "la rochelle île de ré airport\n",
      "ulongwe airport\n",
      "lusaka city airport\n",
      "lyon saint exupéry airport\n",
      "millington memphis airport\n",
      "nice côte d'azur airport\n",
      "oakland troy airport\n",
      "deesa airport\n",
      "palmar airport\n",
      "alphonse airport\n",
      "paris orly airport\n",
      "el jagüel / punta del este airport\n",
      "santo domingo airport\n",
      "shenyang dongta airport\n",
      "stockholm arlanda airport\n",
      "szczecin dąbie airport\n",
      "tampere pirkkala airport\n",
      "tashkent east airport\n",
      "anderstorp airport\n",
      "tours val de loire airport\n",
      "tripolis airport\n",
      "yao airport\n",
      "yuzhno sakhalinsk airport\n",
      "Number of airports in reviews but not in dataset: 61\n"
     ]
    }
   ],
   "source": [
    "## airports in reviews but not in dataset\n",
    "n = 0\n",
    "for airport in airports_in_reviews:\n",
    "    if airport.lower() not in airports_in_dataset:\n",
    "        print(airport)\n",
    "        n += 1\n",
    "        \n",
    "print(\"Number of airports in reviews but not in dataset:\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67663\n",
      "67652\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>airline id</th>\n",
       "      <th>source airport</th>\n",
       "      <th>source airport id</th>\n",
       "      <th>destination airport</th>\n",
       "      <th>destination airport id</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>stops</th>\n",
       "      <th>equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>AER</td>\n",
       "      <td>2965</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>ASF</td>\n",
       "      <td>2966</td>\n",
       "      <td>MRV</td>\n",
       "      <td>2962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>KZN</td>\n",
       "      <td>2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2B</td>\n",
       "      <td>410</td>\n",
       "      <td>CEK</td>\n",
       "      <td>2968</td>\n",
       "      <td>OVB</td>\n",
       "      <td>4078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67658</th>\n",
       "      <td>ZL</td>\n",
       "      <td>4178</td>\n",
       "      <td>WYA</td>\n",
       "      <td>6334</td>\n",
       "      <td>ADL</td>\n",
       "      <td>3341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>SF3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67659</th>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>DME</td>\n",
       "      <td>4029</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67660</th>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>DME</td>\n",
       "      <td>4029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67661</th>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>OSS</td>\n",
       "      <td>2913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67662</th>\n",
       "      <td>ZM</td>\n",
       "      <td>19016</td>\n",
       "      <td>OSS</td>\n",
       "      <td>2913</td>\n",
       "      <td>FRU</td>\n",
       "      <td>2912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67652 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline airline id source airport source airport id destination airport  \\\n",
       "0          2B        410            AER              2965                 KZN   \n",
       "1          2B        410            ASF              2966                 KZN   \n",
       "2          2B        410            ASF              2966                 MRV   \n",
       "3          2B        410            CEK              2968                 KZN   \n",
       "4          2B        410            CEK              2968                 OVB   \n",
       "...       ...        ...            ...               ...                 ...   \n",
       "67658      ZL       4178            WYA              6334                 ADL   \n",
       "67659      ZM      19016            DME              4029                 FRU   \n",
       "67660      ZM      19016            FRU              2912                 DME   \n",
       "67661      ZM      19016            FRU              2912                 OSS   \n",
       "67662      ZM      19016            OSS              2913                 FRU   \n",
       "\n",
       "      destination airport id codeshare  stops equipment  \n",
       "0                       2990       NaN      0       CR2  \n",
       "1                       2990       NaN      0       CR2  \n",
       "2                       2962       NaN      0       CR2  \n",
       "3                       2990       NaN      0       CR2  \n",
       "4                       4078       NaN      0       CR2  \n",
       "...                      ...       ...    ...       ...  \n",
       "67658                   3341       NaN      0       SF3  \n",
       "67659                   2912       NaN      0       734  \n",
       "67660                   4029       NaN      0       734  \n",
       "67661                   2913       NaN      0       734  \n",
       "67662                   2912       NaN      0       734  \n",
       "\n",
       "[67652 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"airline\", \"airline id\", \"source airport\", \"source airport id\", \"destination airport\", \"destination airport id\", \"codeshare\", \"stops\", \"equipment\"]\n",
    "flights = pd.read_csv('data/flights.csv', names=cols, header=None)\n",
    "print(len(flights))\n",
    "flights = flights.dropna(subset=['source airport', 'destination airport'])\n",
    "flights = flights[flights['stops'] == 0]  ## only direct flights\n",
    "print(len(flights))\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making nodes with attributes..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6033/6033 [00:00<00:00, 117006.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making edges..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67652/67652 [00:07<00:00, 9440.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  3256\n",
      "Number of edges:  37038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## makes a graph of the flights\n",
    "## the graph is a directed graph since the flights are one way\n",
    "## nodes are cities, and edges are flights between cities\n",
    "## the weight of the edge is the number of flights between the cities\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "G = nx.DiGraph()\n",
    "\n",
    "print(\"Making nodes with attributes..\")\n",
    "for iata, data in tqdm(IATA.items()):\n",
    "    G.add_node(\n",
    "        iata, \n",
    "        city=data['city'], \n",
    "        country=data['country'], \n",
    "        latitude=data['latitude'], \n",
    "        longitude=data['longitude'], \n",
    "        continent=data['continent'],\n",
    "        name=data['name'],\n",
    "        \n",
    "        group=data['continent']\n",
    "        )\n",
    "\n",
    "print(\"Making edges..\")\n",
    "for index, row in tqdm(flights.iterrows(), total=flights.shape[0]):\n",
    "    source = row['source airport']\n",
    "    dest = row['destination airport']\n",
    "    if source in IATA.keys() and dest in IATA.keys():\n",
    "        if G.has_edge(source, dest):\n",
    "            G[source][dest]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(source, dest, weight=1)\n",
    "            \n",
    "## remove nodes with no edges\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "## \n",
    "import pickle\n",
    "with open('data/graphnetwork.gpickle', 'wb') as f:\n",
    "    pickle.dump(G, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Number of nodes: \", G.number_of_nodes())\n",
    "print(\"Number of edges: \", G.number_of_edges())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
